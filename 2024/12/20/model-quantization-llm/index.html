
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>How I Shrank My LLM: A Student&#39;s Dive into Model Quantization - Zhaokun&#39;s Blog 2025</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Zhaokun, Full Stack, Web Development, Machine Learning, NLP, LLM,"> 
    <meta name="description" content="Thoughts on web development, machine learning, and technology,How I Shrank My LLM: A Student’s Dive into Model QuantizationOne of the most exciting and frustrati,"> 
    <meta name="author" content="Zhaokun"> 
    <link rel="alternative" href="atom.xml" title="Zhaokun&#39;s Blog 2025" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//at.alicdn.com/t/font_1429596_nzgqgvnmkjb.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.7.2/animate.min.css">

    
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/codemirror.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/theme/dracula.css">

    
<link rel="stylesheet" href="/css/obsidian.css">

    
<link rel="stylesheet" href="/css/ball-atom.min.css">

    
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">

    
    <script>var musiclist = ""</script>
    
<script src="/js/loadaplayer.js"></script>

    <!-- 引用依赖 -->
    
<link rel="stylesheet" href="/aplayer/dist/APlayer.min.css">

    
<script src="/aplayer/dist/APlayer.min.js"></script>
<script src="/js/Meting.min.js"></script>

    
<meta name="generator" content="Hexo 7.3.0"></head>


<body class="loading">
    <div class="loader">
        <div class="la-ball-atom la-2x">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
    <span id="config-title" style="display:none">Zhaokun&#39;s Blog 2025</span>
    <div id="loader"></div>
    <div id="single">
    <div class="scrollbar gradient-bg-rev"></div>
<div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <div class="navigation animated fadeIn fast delay-1s">
        <img id="home-icon" class="icon-home" src="/img/favicon.png" alt="" data-url="https://bufferhund.github.io">
        <div id="play-icon" title="Play/Pause" class="iconfont icon-play"></div>
        <h3 class="subtitle">How I Shrank My LLM: A Student's Dive into Model Quantization</h3>
        <div class="social">
            <!--        <div class="like-icon">-->
            <!--            <a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
            <!--        </div>-->
            <div>
                <div class="share">
                    
                        <a href="javascript:;" class="iconfont icon-share1"></a>
                        <div class="share-component-cc" data-disabled="facebook,douban,linkedin,diandian,tencent,google"></div>
                    
                </div>
            </div>
        </div>
    </div>
</div>

    <div class="section">
        <div class=article-header-wrapper>
    <div class="article-header">
        <div class="article-cover animated fadeIn" style="
            animation-delay: 600ms;
            animation-duration: 1.2s;
            background-image: 
                radial-gradient(ellipse closest-side, rgba(0, 0, 0, 0.65), #100e17),
                url('/img/cover.jpg') ">
        </div>
        <div class="else">
            <p class="animated fadeInDown">
                
                <a href="/categories/ML/NLP"><b>「
                    </b>ML/NLP<b> 」</b></a>
                
                December 20, 2024
            </p>
            <h3 class="post-title animated fadeInDown"><a href="/2024/12/20/model-quantization-llm/" title="How I Shrank My LLM: A Student&#39;s Dive into Model Quantization" class="">How I Shrank My LLM: A Student&#39;s Dive into Model Quantization</a>
            </h3>
            
            <p class="post-count animated fadeInDown">
                
                <span>
                    <b class="iconfont icon-text2"></b> <i>Words count</i>
                    4.3k
                </span>
                
                
                <span>
                    <b class="iconfont icon-timer__s"></b> <i>Reading time</i>
                    4 mins.
                </span>
                
                
                
                <span id="busuanzi_container_page_pv">
                    <b class="iconfont icon-read"></b> <i>Read count</i>
                    <span id="busuanzi_value_page_pv">0</span>
                </span>
                
            </p>
            
            
            <ul class="animated fadeInDown post-tags-list" itemprop="keywords"><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Hardware/" rel="tag">Hardware</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Model-Compression/" rel="tag">Model Compression</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Quantization/" rel="tag">Quantization</a></li></ul>
            
        </div>
    </div>
</div>

<div class="screen-gradient-after">
    <div class="screen-gradient-content">
        <div class="screen-gradient-content-inside">
            <div class="bold-underline-links screen-gradient-sponsor">
                <p>
                    <span class="animated fadeIn delay-1s"></span>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="article">
    <div class='main'>
        <div class="content markdown animated fadeIn">
            <h1 id="How-I-Shrank-My-LLM-A-Student’s-Dive-into-Model-Quantization"><a href="#How-I-Shrank-My-LLM-A-Student’s-Dive-into-Model-Quantization" class="headerlink" title="How I Shrank My LLM: A Student’s Dive into Model Quantization"></a>How I Shrank My LLM: A Student’s Dive into Model Quantization</h1><p>One of the most exciting and frustrating moments in my Master’s program was when I finally got my hands on a powerful, pre-trained language model. The excitement came from its incredible capabilities; the frustration came when I realized it was too big to run on my university-provided GPU for any serious fine-tuning. This sent me down the rabbit hole of model compression, and my first major stop was quantization.</p>
<h2 id="What-Exactly-is-Quantization"><a href="#What-Exactly-is-Quantization" class="headerlink" title="What Exactly is Quantization?"></a>What Exactly is Quantization?</h2><p>The way I came to understand quantization is by thinking about digital photos. A professional camera might save a photo as a massive, high-fidelity RAW file. But for sharing online, you convert it to a JPEG. The JPEG is much smaller and faster to load, but you lose a tiny bit of detail.</p>
<p>Quantization does something similar to a language model. It takes the model’s parameters (its “weights”), which are usually stored as high-precision 32-bit floating-point numbers, and converts them to a lower-precision format, like 8-bit integers (int8). This makes the model significantly smaller and the calculations much faster, especially on modern GPUs that have specialized hardware for integer math.</p>
<h2 id="My-First-Attempt-Post-Training-Quantization-PTQ"><a href="#My-First-Attempt-Post-Training-Quantization-PTQ" class="headerlink" title="My First Attempt: Post-Training Quantization (PTQ)"></a>My First Attempt: Post-Training Quantization (PTQ)</h2><p>My first foray was with Post-Training Quantization (PTQ). It’s the most straightforward approach: you take your fully trained, high-precision model and simply convert its weights to the lower-precision format after the fact. It’s fast and doesn’t require any retraining.</p>
<p>The result? It worked! The model that previously crashed my session was now running smoothly. The trade-off was a small but noticeable drop in accuracy on my evaluation benchmarks. For a quick prototype, it was perfect. But for my final project, I knew I needed to claw back that lost performance.</p>
<h2 id="The-Next-Level-Quantization-Aware-Training-QAT"><a href="#The-Next-Level-Quantization-Aware-Training-QAT" class="headerlink" title="The Next Level: Quantization-Aware Training (QAT)"></a>The Next Level: Quantization-Aware Training (QAT)</h2><p>This led me to Quantization-Aware Training (QAT). The idea here is to make the model <em>aware</em> of the quantization process <em>during</em> training or fine-tuning. You’re essentially simulating the effects of quantization in the training loop, allowing the model to learn how to compensate for the loss of precision.</p>
<p>It requires more work because you have to integrate the quantization simulation into your training code, but the results were worth it. With QAT, I was able to get a quantized model that performed nearly as well as the original full-precision version, while still being much smaller and faster.</p>
<h2 id="The-Big-Trade-off-Performance-vs-Efficiency"><a href="#The-Big-Trade-off-Performance-vs-Efficiency" class="headerlink" title="The Big Trade-off: Performance vs. Efficiency"></a>The Big Trade-off: Performance vs. Efficiency</h2><p>My journey with quantization was a lesson in trade-offs. There’s no free lunch. Squeezing a model down to a smaller size will almost always have some impact on its performance. The key is to find the sweet spot for your specific application. Are you deploying a model on a smartphone where efficiency is everything? Or are you chasing state-of-the-art results for a research paper where every decimal point of accuracy matters?</p>
<p>For a student like me, quantization is more than just a technical trick. It’s an enabling technology. It democratizes access to powerful models, letting us experiment and build interesting applications without needing access to a massive industrial data center. It’s a fundamental skill for anyone looking to do practical work in this field. </p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls"
                data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
            <ul id="audio-list" style="display:none">
                
                
                <li title='0' data-url='/statics/chengdu.mp3'></li>
                
                    
            </ul>
            
                        
            
            
        </div>
        <div class="sidebar">
            <div class="box animated fadeInRight">
                <div class="subbox">
                    <img src="https://s2.ax1x.com/2019/09/19/nLtSiD.png" height=300 width=300></img>
                    <p>Zhaokun</p>
                    <span>Full Stack Developer | ML/NLP/LLM</span>
                    <dl>
                        
                            
                                <dd><a href="https://github.com/BufferHund" target="_blank"><span
                                    class=" iconfont icon-github"></span></a></dd>
                            
                            
                            
                        
                        
                    </dl>
                </div>
                <ul>
                    <li><a href="/">19 <p>Articles</p></a></li>
                    <li><a href="/categories">3 <p>Categories</p></a></li>
                    <li><a href="/tags">55 <p>Tags</p></a></li>
                </ul>
            </div>
            
            
            
            <div class="box sticky animated fadeInRight faster">
                <div id="toc" class="subbox">
                    <h4>Contents</h4>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#How-I-Shrank-My-LLM-A-Student%E2%80%99s-Dive-into-Model-Quantization"><span class="toc-number">1.</span> <span class="toc-text">How I Shrank My LLM: A Student’s Dive into Model Quantization</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-Exactly-is-Quantization"><span class="toc-number">1.1.</span> <span class="toc-text">What Exactly is Quantization?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#My-First-Attempt-Post-Training-Quantization-PTQ"><span class="toc-number">1.2.</span> <span class="toc-text">My First Attempt: Post-Training Quantization (PTQ)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Next-Level-Quantization-Aware-Training-QAT"><span class="toc-number">1.3.</span> <span class="toc-text">The Next Level: Quantization-Aware Training (QAT)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Big-Trade-off-Performance-vs-Efficiency"><span class="toc-number">1.4.</span> <span class="toc-text">The Big Trade-off: Performance vs. Efficiency</span></a></li></ol></li></ol>
                </div>
            </div>
            
            
        </div>
    </div>
</div>

    </div>
</div>
    <div id="back-to-top" class="animated fadeIn faster">
        <div class="flow"></div>
        <span class="percentage animated fadeIn faster">0%</span>
        <span class="iconfont icon-top02 animated fadeIn faster"></span>
    </div>
</body>
<footer>
    <p class="copyright" id="copyright">
        &copy; 2025
        <span class="gradient-text">
            Zhaokun
        </span>.
        Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
        Theme
        <span class="gradient-text">
            <a href="https://github.com/TriDiamond/hexo-theme-obsidian" title="Obsidian" target="_blank" rel="noopener">Obsidian</a>
        </span>
        <small><a href="https://github.com/TriDiamond/hexo-theme-obsidian/blob/master/CHANGELOG.md" title="v1.4.9.4" target="_blank" rel="noopener">v1.4.9.4</a></small>
        
        </br>
        
        <span class="gradient-text">
            <a href="https://beian.miit.gov.cn/" title="beian.miit.gov.cn" target="_blank" rel="noopener">beian.miit.gov.cn</a>
        </span>
        
        
        </br>
        <span style="display: inline-block;"> <img src=/null></span>
        
        <span class="gradient-text">
            <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44010602009049" title="www.beian.gov.cn&#x2F;portal&#x2F;registerSystemInfo?recordcode&#x3D;44010602009049" target="_blank" rel="noopener">www.beian.gov.cn&#x2F;portal&#x2F;registerSystemInfo?recordcode&#x3D;44010602009049</a>
        </span>
        
    </p>
</footer>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX", "TeX"],
      linebreaks: {
        automatic: true
      },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"]
      ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      noUndefined: {
        attributes: {
          mathcolor: "red",
          mathbackground: "#FFEEEE",
          mathsize: "90%"
        }
      },
      Macros: {
        href: "{}"
      }
    },
    messageStyle: "none"
  });
</script>
<script>
  function initialMathJax() {
    MathJax.Hub.Queue(function () {
      var all = MathJax.Hub.getAllJax(),
        i;
      // console.log(all);
      for (i = 0; i < all.length; i += 1) {
        console.log(all[i].SourceElement().parentNode)
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  }

  function reprocessMathJax() {
    if (typeof MathJax !== 'undefined') {
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    }
  }
</script>


 
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/obsidian.js"></script>
<script src="/js/jquery.truncate.js"></script>
<script src="/js/search.js"></script>
 
<script src="//cdn.bootcss.com/typed.js/2.0.10/typed.min.js"></script>
 
<script src="//cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script>
 
<script src="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>


<script src="https://cdn.bootcss.com/codemirror/5.48.4/codemirror.min.js"></script>
 
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/javascript/javascript.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/css/css.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/xml/xml.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/htmlmixed/htmlmixed.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/clike/clike.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/php/php.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/shell/shell.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/python/python.min.js"></script>
   
<script src="/js/busuanzi.min.js"></script>

<script>
  $(document).ready(function () {
    if ($('span[id^="busuanzi_"]').length) {
      initialBusuanzi();
    }
  });
</script>
 
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css">


<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
  

<script>
  function initialTyped() {
    var typedTextEl = $('.typed-text');
    if (typedTextEl && typedTextEl.length > 0) {
      var typed = new Typed('.typed-text', {
        strings: ['Full Stack Developer | ML/NLP/LLM', 'Thoughts on web development, machine learning, and technology'],
        typeSpeed: 90,
        loop: true,
        loopCount: Infinity,
        backSpeed: 20,
      });
    }
  }

  if ($('.article-header') && $('.article-header').length) {
    $(document).ready(function () {
      initialTyped();
    });
  }
</script>




<!-- 引用依赖 -->
<script>document.write(aplayerconf)</script>




</html>
